{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "base_dir = \"vuelax\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oportunidades_url = \"http://www.vuelax.com/category/oportunidades/page/%d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for page in range(1, 10000):\n",
    "    url = oportunidades_url % page\n",
    "    op_page = requests.get(url)\n",
    "    if page % 10 == 0:\n",
    "        print(\"Requesting\", url)\n",
    "    if op_page.status_code != 200:\n",
    "        break\n",
    "    op_soup = BeautifulSoup(op_page.text, \"lxml\")\n",
    "    main_ul = op_soup.find(\"ul\", {\"class\":\"penci-grid\"})\n",
    "    articles = main_ul.findAll(\"article\", {\"class\":\"item\"})\n",
    "    for article in articles:\n",
    "        grid_title = article.find(\"h2\", {\"class\":\"grid-title\"})\n",
    "        a = grid_title.find(\"a\")\n",
    "        grid_post_box_meta = article.find(\"div\", {\"class\":\"grid-post-box-meta\"})\n",
    "        content.append([a.text, a.get('href'), grid_post_box_meta.text.strip()])\n",
    "\n",
    "data = pd.DataFrame(content, columns= [\"label\", \"url\", \"date\"])\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "data.to_csv(join(base_dir, \"original.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(base_dir, \"original.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "     origin  destination   price  \\\n",
      "0      CDMX       Tokyo   10,972   \n",
      "1      CDMX        Lima    5,059   \n",
      "2       CUN     Bélgica    9,731   \n",
      "3    Canadá    Islandia    4,425   \n",
      "4  Islandia  Inglaterra    1,156   \n",
      "\n",
      "                                                 url            date  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  enero 14, 2018  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  enero 13, 2018  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  enero 13, 2018  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  enero 12, 2018  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  enero 12, 2018  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1255 entries, 0 to 1254\n",
      "Data columns (total 5 columns):\n",
      "origin         1255 non-null object\n",
      "destination    1255 non-null object\n",
      "price          1255 non-null object\n",
      "url            1255 non-null object\n",
      "date           1255 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 49.1+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Irlanda (escala larga en Canadá) – $16,...   \n",
      "1  GDL a Hiroshima, Japón (escala larga en Shangh...   \n",
      "2  CDMX a Atenas, Grecia (escala larga en NYC) – ...   \n",
      "3  CDMX a Barcelona + Barcelona a Moscú – Ekateri...   \n",
      "4  CDMX a Madrid (escala larga en Toronto) – $14,...   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/15/cdmx-a-irland...  diciembre 15, 2017  \n",
      "1  http://www.vuelax.com/2017/12/13/cdmx-a-hirosh...  diciembre 13, 2017  \n",
      "2  http://www.vuelax.com/2017/12/13/cdmx-a-atenas...  diciembre 13, 2017  \n",
      "3  http://www.vuelax.com/2017/12/12/cdmx-a-barcel...  diciembre 12, 2017  \n",
      "4  http://www.vuelax.com/2017/12/12/cdmx-a-madrid...  diciembre 12, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137 entries, 0 to 136\n",
      "Data columns (total 3 columns):\n",
      "label    137 non-null object\n",
      "url      137 non-null object\n",
      "date     137 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "clean = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 137 entries, 0 to 136\n",
      "Data columns (total 3 columns):\n",
      "label    137 non-null object\n",
      "url      137 non-null object\n",
      "date     137 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), index_col = 0)\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "origin         11 non-null object\n",
      "destination    11 non-null object\n",
      "price          11 non-null object\n",
      "note           11 non-null object\n",
      "url            11 non-null object\n",
      "date           11 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 608.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*\\(([\\w\\s]+)\\)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        note = find.group(3)\n",
    "        por = find.group(4)\n",
    "        clean_values.append([de, a, por, note, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"note\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1266 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "date           1266 non-null object\n",
      "destination    1266 non-null object\n",
      "note           11 non-null object\n",
      "origin         1266 non-null object\n",
      "price          1266 non-null object\n",
      "url            1266 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 69.2+ KB\n",
      "== Clean ==\n",
      "             date  destination note    origin   price  \\\n",
      "0  enero 14, 2018       Tokyo   NaN      CDMX  10,972   \n",
      "1  enero 13, 2018        Lima   NaN      CDMX   5,059   \n",
      "2  enero 13, 2018     Bélgica   NaN       CUN   9,731   \n",
      "3  enero 12, 2018    Islandia   NaN    Canadá   4,425   \n",
      "4  enero 12, 2018  Inglaterra   NaN  Islandia   1,156   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1266 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "date           1266 non-null object\n",
      "destination    1266 non-null object\n",
      "note           11 non-null object\n",
      "origin         1266 non-null object\n",
      "price          1266 non-null object\n",
      "url            1266 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 69.2+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1  ¡GDL a Panamá! – $3,790. ¡Opción de hostal des...   \n",
      "2                                MTY a Cancún $1,455   \n",
      "3                                ¡2×1! ¡Full Brasil!   \n",
      "4     ¡CDMX y 23 ciudades más a Nueva York! – $4,776   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel...  diciembre 11, 2017  \n",
      "1  http://www.vuelax.com/2017/12/07/gdl-a-panama-...   diciembre 7, 2017  \n",
      "2  http://www.vuelax.com/2017/12/04/mty-a-cancun-...   diciembre 4, 2017  \n",
      "3  http://www.vuelax.com/2017/11/24/2x1-full-brasil/  noviembre 24, 2017  \n",
      "4  http://www.vuelax.com/2017/11/17/cdmx-y-23-ciu...  noviembre 17, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), index_col = 0)\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      "origin         42 non-null object\n",
      "destination    42 non-null object\n",
      "price          42 non-null object\n",
      "url            42 non-null object\n",
      "date           42 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      "label    84 non-null object\n",
      "url      84 non-null object\n",
      "date     84 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('¡([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)!\\s[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "             date  destination note    origin   price  \\\n",
      "0  enero 14, 2018       Tokyo   NaN      CDMX  10,972   \n",
      "1  enero 13, 2018        Lima   NaN      CDMX   5,059   \n",
      "2  enero 13, 2018     Bélgica   NaN       CUN   9,731   \n",
      "3  enero 12, 2018    Islandia   NaN    Canadá   4,425   \n",
      "4  enero 12, 2018  Inglaterra   NaN  Islandia   1,156   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1308 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1308 non-null object\n",
      "destination    1308 non-null object\n",
      "note           11 non-null object\n",
      "origin         1308 non-null object\n",
      "price          1308 non-null object\n",
      "url            1308 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 71.5+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1                                MTY a Cancún $1,455   \n",
      "2                                ¡2×1! ¡Full Brasil!   \n",
      "3  ¡Sin pasar EEUU! CDMX y 23 ciudades más a Vanc...   \n",
      "4  CDMX y más ciudades a Lima, Perú. ¡Opción de h...   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel...  diciembre 11, 2017  \n",
      "1  http://www.vuelax.com/2017/12/04/mty-a-cancun-...   diciembre 4, 2017  \n",
      "2  http://www.vuelax.com/2017/11/24/2x1-full-brasil/  noviembre 24, 2017  \n",
      "3  http://www.vuelax.com/2017/11/15/sin-pasar-eeu...  noviembre 15, 2017  \n",
      "4  http://www.vuelax.com/2017/11/13/cdmx-y-mas-ci...  noviembre 13, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      "label    84 non-null object\n",
      "url      84 non-null object\n",
      "date     84 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "\n",
    "clean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
