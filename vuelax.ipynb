{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "base_dir = \"vuelax\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oportunidades_url = \"http://www.vuelax.com/category/oportunidades/page/%d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for page in range(1, 10000):\n",
    "    url = oportunidades_url % page\n",
    "    op_page = requests.get(url)\n",
    "    if page % 10 == 0:\n",
    "        print(\"Requesting\", url)\n",
    "    if op_page.status_code != 200:\n",
    "        break\n",
    "    op_soup = BeautifulSoup(op_page.text, \"lxml\")\n",
    "    main_ul = op_soup.find(\"ul\", {\"class\":\"penci-grid\"})\n",
    "    articles = main_ul.findAll(\"article\", {\"class\":\"item\"})\n",
    "    for article in articles:\n",
    "        grid_title = article.find(\"h2\", {\"class\":\"grid-title\"})\n",
    "        a = grid_title.find(\"a\")\n",
    "        grid_post_box_meta = article.find(\"div\", {\"class\":\"grid-post-box-meta\"})\n",
    "        content.append([a.text, a.get('href'), grid_post_box_meta.text.strip()])\n",
    "\n",
    "data = pd.DataFrame(content, columns= [\"label\", \"url\", \"date\"])\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "data.to_csv(join(base_dir, \"original.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(base_dir, \"original.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "     origin  destination   price  \\\n",
      "0      CDMX       Tokyo   10,972   \n",
      "1      CDMX        Lima    5,059   \n",
      "2       CUN     Bélgica    9,731   \n",
      "3    Canadá    Islandia    4,425   \n",
      "4  Islandia  Inglaterra    1,156   \n",
      "\n",
      "                                                 url            date  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  enero 14, 2018  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  enero 13, 2018  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  enero 13, 2018  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  enero 12, 2018  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  enero 12, 2018  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1255 entries, 0 to 1254\n",
      "Data columns (total 5 columns):\n",
      "origin         1255 non-null object\n",
      "destination    1255 non-null object\n",
      "price          1255 non-null object\n",
      "url            1255 non-null object\n",
      "date           1255 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 49.1+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Irlanda (escala larga en Canadá) – $16,...   \n",
      "1  GDL a Hiroshima, Japón (escala larga en Shangh...   \n",
      "2  CDMX a Atenas, Grecia (escala larga en NYC) – ...   \n",
      "3  CDMX a Barcelona + Barcelona a Moscú – Ekateri...   \n",
      "4  CDMX a Madrid (escala larga en Toronto) – $14,...   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/15/cdmx-a-irland...  diciembre 15, 2017  \n",
      "1  http://www.vuelax.com/2017/12/13/cdmx-a-hirosh...  diciembre 13, 2017  \n",
      "2  http://www.vuelax.com/2017/12/13/cdmx-a-atenas...  diciembre 13, 2017  \n",
      "3  http://www.vuelax.com/2017/12/12/cdmx-a-barcel...  diciembre 12, 2017  \n",
      "4  http://www.vuelax.com/2017/12/12/cdmx-a-madrid...  diciembre 12, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137 entries, 0 to 136\n",
      "Data columns (total 3 columns):\n",
      "label    137 non-null object\n",
      "url      137 non-null object\n",
      "date     137 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "clean = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 137 entries, 0 to 136\n",
      "Data columns (total 3 columns):\n",
      "label    137 non-null object\n",
      "url      137 non-null object\n",
      "date     137 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), index_col = 0)\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "origin         11 non-null object\n",
      "destination    11 non-null object\n",
      "price          11 non-null object\n",
      "note           11 non-null object\n",
      "url            11 non-null object\n",
      "date           11 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 608.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*\\(([\\w\\s]+)\\)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        note = find.group(3)\n",
    "        por = find.group(4)\n",
    "        clean_values.append([de, a, por, note, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"note\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1266 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "date           1266 non-null object\n",
      "destination    1266 non-null object\n",
      "note           11 non-null object\n",
      "origin         1266 non-null object\n",
      "price          1266 non-null object\n",
      "url            1266 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 69.2+ KB\n",
      "== Clean ==\n",
      "             date  destination note    origin   price  \\\n",
      "0  enero 14, 2018       Tokyo   NaN      CDMX  10,972   \n",
      "1  enero 13, 2018        Lima   NaN      CDMX   5,059   \n",
      "2  enero 13, 2018     Bélgica   NaN       CUN   9,731   \n",
      "3  enero 12, 2018    Islandia   NaN    Canadá   4,425   \n",
      "4  enero 12, 2018  Inglaterra   NaN  Islandia   1,156   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1266 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "date           1266 non-null object\n",
      "destination    1266 non-null object\n",
      "note           11 non-null object\n",
      "origin         1266 non-null object\n",
      "price          1266 non-null object\n",
      "url            1266 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 69.2+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1  ¡GDL a Panamá! – $3,790. ¡Opción de hostal des...   \n",
      "2                                MTY a Cancún $1,455   \n",
      "3                                ¡2×1! ¡Full Brasil!   \n",
      "4     ¡CDMX y 23 ciudades más a Nueva York! – $4,776   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel...  diciembre 11, 2017  \n",
      "1  http://www.vuelax.com/2017/12/07/gdl-a-panama-...   diciembre 7, 2017  \n",
      "2  http://www.vuelax.com/2017/12/04/mty-a-cancun-...   diciembre 4, 2017  \n",
      "3  http://www.vuelax.com/2017/11/24/2x1-full-brasil/  noviembre 24, 2017  \n",
      "4  http://www.vuelax.com/2017/11/17/cdmx-y-23-ciu...  noviembre 17, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 126 entries, 0 to 125\n",
      "Data columns (total 3 columns):\n",
      "label    126 non-null object\n",
      "url      126 non-null object\n",
      "date     126 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), index_col = 0)\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      "origin         42 non-null object\n",
      "destination    42 non-null object\n",
      "price          42 non-null object\n",
      "url            42 non-null object\n",
      "date           42 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      "label    84 non-null object\n",
      "url      84 non-null object\n",
      "date     84 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('¡([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)!\\s[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "             date  destination note    origin   price  \\\n",
      "0  enero 14, 2018       Tokyo   NaN      CDMX  10,972   \n",
      "1  enero 13, 2018        Lima   NaN      CDMX   5,059   \n",
      "2  enero 13, 2018     Bélgica   NaN       CUN   9,731   \n",
      "3  enero 12, 2018    Islandia   NaN    Canadá   4,425   \n",
      "4  enero 12, 2018  Inglaterra   NaN  Islandia   1,156   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/14/cdmx-a-tokyo-...  \n",
      "1  http://www.vuelax.com/2018/01/13/cdmx-a-lima-5...  \n",
      "2  http://www.vuelax.com/2018/01/13/cun-a-belgica...  \n",
      "3  http://www.vuelax.com/2018/01/12/canada-a-isla...  \n",
      "4  http://www.vuelax.com/2018/01/12/islandia-a-in...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1308 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1308 non-null object\n",
      "destination    1308 non-null object\n",
      "note           11 non-null object\n",
      "origin         1308 non-null object\n",
      "price          1308 non-null object\n",
      "url            1308 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 71.5+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1                                MTY a Cancún $1,455   \n",
      "2                                ¡2×1! ¡Full Brasil!   \n",
      "3  ¡Sin pasar EEUU! CDMX y 23 ciudades más a Vanc...   \n",
      "4  CDMX y más ciudades a Lima, Perú. ¡Opción de h...   \n",
      "\n",
      "                                                 url                date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel...  diciembre 11, 2017  \n",
      "1  http://www.vuelax.com/2017/12/04/mty-a-cancun-...   diciembre 4, 2017  \n",
      "2  http://www.vuelax.com/2017/11/24/2x1-full-brasil/  noviembre 24, 2017  \n",
      "3  http://www.vuelax.com/2017/11/15/sin-pasar-eeu...  noviembre 15, 2017  \n",
      "4  http://www.vuelax.com/2017/11/13/cdmx-y-mas-ci...  noviembre 13, 2017  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      "label    84 non-null object\n",
      "url      84 non-null object\n",
      "date     84 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         origin                       destination    price\n",
      "12              CDMX, GDL y MTY         Whitehorse, Yukón, Canadá   12,611\n",
      "13                         CDMX  El Calafate, Patagonia Argentina   10,829\n",
      "14       CDMX y 23 ciudades más                 San Francisco, CA    3,795\n",
      "15       CDMX y 23 ciudades más                   Toronto, Canadá   8,486.\n",
      "16                         CDMX                 Santa Clara, Cuba    4,666\n",
      "17       CDMX y 23 ciudades más                  Montreal, Canadá   8,367.\n",
      "18                         CDMX                            Madrid  11,866.\n",
      "19                         CDMX                         Barcelona  11,921.\n",
      "20         CDMX, MTY, GDL y CUN                  El Cairo, Egipto  10,038.\n",
      "21                         CDMX             San Juan, Puerto Rico    4,292\n",
      "22                         CDMX                    Beirut, Líbano  13,219.\n",
      "23                   CDMX y GDL         San Francisco, California    3,970\n",
      "24  CDMX, GDL y 22 ciudades más                           Chicago    3,388\n",
      "25       CDMX y 23 ciudades más                      Roma, Italia   16,275\n",
      "26                         CDMX                    Varadero, Cuba    5,526\n",
      "27                         CDMX                   Honolulu, Hawai   10,931\n",
      "28                   CDMX y GDL                   Bali, Indonesia   13,808\n",
      "29                   CDMX y GDL                      Osaka, Japón   12,227\n",
      "30                   CDMX y GDL                 Anchorage, Alaska    9,680\n",
      "31         CDMX, MTY, GDL y CUN                  El Cairo, Egipto   9,686.\n",
      "32                         CDMX                 Sydney, Australia   18,312\n",
      "33                   CDMX y GDL                     San Francisco    4,110\n",
      "34                         CDMX                       Nueva Delhi   10,921\n",
      "35                         CDMX                Edimburgo, Escocia   17,963\n",
      "36                         CDMX                 Santa Clara, Cuba    5,438\n",
      "37                         CDMX                 Cancún en Navidad    2,489\n",
      "38                         CDMX                        Oranjestad   7,564.\n",
      "39                         CDMX                           Londres   13,917\n",
      "40                         CDMX                          Chetumal    1,462\n",
      "41                         CDMX                         La Habana    3,720\n",
      "                         origin                       destination   price\n",
      "12              CDMX, GDL y MTY         Whitehorse, Yukón, Canadá  12,611\n",
      "13                         CDMX  El Calafate, Patagonia Argentina  10,829\n",
      "14       CDMX y 23 ciudades más                 San Francisco, CA   3,795\n",
      "15       CDMX y 23 ciudades más                   Toronto, Canadá   8,486\n",
      "16                         CDMX                 Santa Clara, Cuba   4,666\n",
      "17       CDMX y 23 ciudades más                  Montreal, Canadá   8,367\n",
      "18                         CDMX                            Madrid  11,866\n",
      "19                         CDMX                         Barcelona  11,921\n",
      "20         CDMX, MTY, GDL y CUN                  El Cairo, Egipto  10,038\n",
      "21                         CDMX             San Juan, Puerto Rico   4,292\n",
      "22                         CDMX                    Beirut, Líbano  13,219\n",
      "23                   CDMX y GDL         San Francisco, California   3,970\n",
      "24  CDMX, GDL y 22 ciudades más                           Chicago   3,388\n",
      "25       CDMX y 23 ciudades más                      Roma, Italia  16,275\n",
      "26                         CDMX                    Varadero, Cuba   5,526\n",
      "27                         CDMX                   Honolulu, Hawai  10,931\n",
      "28                   CDMX y GDL                   Bali, Indonesia  13,808\n",
      "29                   CDMX y GDL                      Osaka, Japón  12,227\n",
      "30                   CDMX y GDL                 Anchorage, Alaska   9,680\n",
      "31         CDMX, MTY, GDL y CUN                  El Cairo, Egipto   9,686\n",
      "32                         CDMX                 Sydney, Australia  18,312\n",
      "33                   CDMX y GDL                     San Francisco   4,110\n",
      "34                         CDMX                       Nueva Delhi  10,921\n",
      "35                         CDMX                Edimburgo, Escocia  17,963\n",
      "36                         CDMX                 Santa Clara, Cuba   5,438\n",
      "37                         CDMX                 Cancún en Navidad   2,489\n",
      "38                         CDMX                        Oranjestad   7,564\n",
      "39                         CDMX                           Londres  13,917\n",
      "40                         CDMX                          Chetumal   1,462\n",
      "41                         CDMX                         La Habana   3,720\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "\n",
    "strip_blanks = lambda x: x.strip()\n",
    "strip_dot = lambda x: x.strip('.')\n",
    "\n",
    "print(clean[['origin','destination','price']].tail(30))\n",
    "clean.origin = clean.origin.apply(strip_blanks)\n",
    "clean.destination = clean.destination.apply(strip_blanks)\n",
    "clean.price = clean.price.apply(strip_dot)\n",
    "print(clean[['origin','destination','price']].tail(30))\n",
    "\n",
    "\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1308 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1308 non-null object\n",
      "destination    1308 non-null object\n",
      "note           11 non-null object\n",
      "origin         1308 non-null object\n",
      "price          1308 non-null object\n",
      "url            1308 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 71.5+ KB\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['enero 14, 2018', 'enero 13, 2018', 'enero 13, 2018', ...,\n",
       "       'noviembre 18, 2016', 'noviembre 15, 2016', 'noviembre 8, 2016'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {'enero':1,\n",
    "          'febrero':2,\n",
    "          'marzo':3,\n",
    "          'abril':4,\n",
    "          'mayo':5,\n",
    "          'junio':6,\n",
    "          'julio':7,'agosto':8,\n",
    "          'septiembre':9,\n",
    "          'octubre':10,\n",
    "          'noviembre':11,\n",
    "          'diciembre':12}\n",
    "date_regex = re.compile('(\\w+) ([0-9]+), ([0-9]{4})')\n",
    "\n",
    "def date_converter(date):\n",
    "    found = date_regex.search(date)\n",
    "    if found:\n",
    "        return datetime.datetime(year=int(found.group(3)), month=months[found.group(1)], day=int(found.group(2)))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "clean.date = clean['date'].apply(date_converter)\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean.to_csv(join(base_dir, \"clean.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
