{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "base_dir = \"vuelax\"\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "    \n",
    "original_file = join(base_dir, \"original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = {'enero':1, 'febrero':2, 'marzo':3,\n",
    "          'abril':4, 'mayo':5, 'junio':6,\n",
    "          'julio':7,'agosto':8, 'septiembre':9,\n",
    "          'octubre':10, 'noviembre':11, 'diciembre':12}\n",
    "\n",
    "date_regex = re.compile('(\\w+) ([0-9]+), ([0-9]{4})')\n",
    "\n",
    "def date_converter(date):\n",
    "    found = date_regex.search(date)\n",
    "    if found:\n",
    "        return datetime.datetime(year=int(found.group(3)), month=months[found.group(1)], day=int(found.group(2)))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date 2018-01-21 00:00:00\n",
      "                                     label  \\\n",
      "0  CDMX a India – $8,621 ¡3 nuevas fechas!   \n",
      "1                    GDL a La Paz – $1,195   \n",
      "2  CDMX a India – $8,621 ¡4 nuevas fechas!   \n",
      "4             GDL y CDMX a China – $11,046   \n",
      "6                 CUN a Ámsterdam – $9,339   \n",
      "\n",
      "                                                 url       date  \n",
      "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-... 2018-01-21  \n",
      "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-... 2018-01-20  \n",
      "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-... 2018-01-20  \n",
      "4  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-... 2018-01-19  \n",
      "6  http://www.vuelax.com/2018/01/19/cun-a-amsterd... 2018-01-19  \n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "last_date = None\n",
    "if os.path.exists(original_file):\n",
    "    data = pd.read_csv(original_file, index_col=0, parse_dates=['date'], encoding='utf-8')\n",
    "    last_date = data.iloc[0]['date']\n",
    "    print(\"Last date\", last_date)\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oportunidades_url = \"http://www.vuelax.com/category/oportunidades/page/%d/\"\n",
    "uncategorized_url = \"http://www.vuelax.com/category/uncategorized/page/%d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya tengo esta fecha!\n",
      "                                     label  \\\n",
      "0  CDMX a India – $8,621 ¡3 nuevas fechas!   \n",
      "1                    GDL a La Paz – $1,195   \n",
      "2  CDMX a India – $8,621 ¡4 nuevas fechas!   \n",
      "4             GDL y CDMX a China – $11,046   \n",
      "6                 CUN a Ámsterdam – $9,339   \n",
      "\n",
      "                                                 url       date  \n",
      "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-... 2018-01-21  \n",
      "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-... 2018-01-20  \n",
      "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-... 2018-01-20  \n",
      "4  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-... 2018-01-19  \n",
      "6  http://www.vuelax.com/2018/01/19/cun-a-amsterd... 2018-01-19  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1435 entries, 0 to 1392\n",
      "Data columns (total 3 columns):\n",
      "label    1435 non-null object\n",
      "url      1435 non-null object\n",
      "date     1435 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 44.8+ KB\n",
      "None\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "brk = False\n",
    "for page in range(1, 100000):\n",
    "    url = uncategorized_url % page\n",
    "    op_page = requests.get(url)\n",
    "    if page % 10 == 0:\n",
    "        print(\"Requesting\", url)\n",
    "    if op_page.status_code != 200:\n",
    "        break\n",
    "    op_soup = BeautifulSoup(op_page.text, \"lxml\")\n",
    "    main_ul = op_soup.find(\"ul\", {\"class\":\"penci-grid\"})\n",
    "    articles = main_ul.findAll(\"article\", {\"class\":\"item\"})\n",
    "    for article in articles:\n",
    "        grid_title = article.find(\"h2\", {\"class\":\"grid-title\"})\n",
    "        a = grid_title.find(\"a\")\n",
    "        grid_post_box_meta = article.find(\"div\", {\"class\":\"grid-post-box-meta\"})\n",
    "        date = date_converter(grid_post_box_meta.text.strip())\n",
    "        if date <= last_date:\n",
    "            brk = True\n",
    "            print(\"Ya tengo esta fecha!\")\n",
    "            break\n",
    "        content.append([a.text, a.get('href'), date])\n",
    "    if brk:\n",
    "        break\n",
    "        \n",
    "if data is not None:\n",
    "    other = pd.DataFrame(content, columns= [\"label\", \"url\", \"date\"])\n",
    "    data = pd.concat([data, other])\n",
    "else:\n",
    "    data =  pd.DataFrame(content, columns= [\"label\", \"url\", \"date\"])\n",
    "data.sort_values(by=['date', 'label'], ascending= False, inplace=True)\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(join(base_dir, \"original.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(base_dir, \"original.csv\"), index_col=0, parse_dates=['date'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "       origin destination   price  \\\n",
      "0        CDMX      India    8,621   \n",
      "1         GDL     La Paz    1,195   \n",
      "2        CDMX      India    8,621   \n",
      "3  GDL y CDMX      China   11,046   \n",
      "4         CUN  Ámsterdam    9,339   \n",
      "\n",
      "                                                 url       date  \n",
      "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-... 2018-01-21  \n",
      "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-... 2018-01-20  \n",
      "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-... 2018-01-20  \n",
      "3  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-... 2018-01-19  \n",
      "4  http://www.vuelax.com/2018/01/19/cun-a-amsterd... 2018-01-19  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1297 entries, 0 to 1296\n",
      "Data columns (total 5 columns):\n",
      "origin         1297 non-null object\n",
      "destination    1297 non-null object\n",
      "price          1297 non-null object\n",
      "url            1297 non-null object\n",
      "date           1297 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 50.7+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Irlanda (escala larga en Canadá) – $16,...   \n",
      "1  GDL a Hiroshima, Japón (escala larga en Shangh...   \n",
      "2  CDMX a Atenas, Grecia (escala larga en NYC) – ...   \n",
      "3  CDMX a Madrid (escala larga en Toronto) – $14,...   \n",
      "4  CDMX a Barcelona + Barcelona a Moscú – Ekateri...   \n",
      "\n",
      "                                                 url       date  \n",
      "0  http://www.vuelax.com/2017/12/15/cdmx-a-irland... 2017-12-15  \n",
      "1  http://www.vuelax.com/2017/12/13/cdmx-a-hirosh... 2017-12-13  \n",
      "2  http://www.vuelax.com/2017/12/13/cdmx-a-atenas... 2017-12-13  \n",
      "3  http://www.vuelax.com/2017/12/12/cdmx-a-madrid... 2017-12-12  \n",
      "4  http://www.vuelax.com/2017/12/12/cdmx-a-barcel... 2017-12-12  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138 entries, 0 to 137\n",
      "Data columns (total 3 columns):\n",
      "label    138 non-null object\n",
      "url      138 non-null object\n",
      "date     138 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 3.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "clean = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"), encoding='utf-8')\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 138 entries, 0 to 137\n",
      "Data columns (total 3 columns):\n",
      "label    138 non-null object\n",
      "url      138 non-null object\n",
      "date     138 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), parse_dates=['date'], index_col = 0, encoding='utf-8')\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "origin         11 non-null object\n",
      "destination    11 non-null object\n",
      "price          11 non-null object\n",
      "note           11 non-null object\n",
      "url            11 non-null object\n",
      "date           11 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 608.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127 entries, 0 to 126\n",
      "Data columns (total 3 columns):\n",
      "label    127 non-null object\n",
      "url      127 non-null object\n",
      "date     127 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 3.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)\\s*\\(([\\w\\s]+)\\)\\s*[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        note = find.group(3)\n",
    "        por = find.group(4)\n",
    "        clean_values.append([de, a, por, note, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"note\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "        date destination note      origin   price  \\\n",
      "0 2018-01-21      India   NaN        CDMX   8,621   \n",
      "1 2018-01-20     La Paz   NaN         GDL   1,195   \n",
      "2 2018-01-20      India   NaN        CDMX   8,621   \n",
      "3 2018-01-19      China   NaN  GDL y CDMX  11,046   \n",
      "4 2018-01-19  Ámsterdam   NaN         CUN   9,339   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-...  \n",
      "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-...  \n",
      "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-...  \n",
      "3  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...  \n",
      "4  http://www.vuelax.com/2018/01/19/cun-a-amsterd...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1308 entries, 0 to 10\n",
      "Data columns (total 6 columns):\n",
      "date           1308 non-null datetime64[ns]\n",
      "destination    1308 non-null object\n",
      "note           11 non-null object\n",
      "origin         1308 non-null object\n",
      "price          1308 non-null object\n",
      "url            1308 non-null object\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 71.5+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1  ¡GDL a Panamá! – $3,790. ¡Opción de hostal des...   \n",
      "2                                MTY a Cancún $1,455   \n",
      "3                                ¡2×1! ¡Full Brasil!   \n",
      "4     ¡CDMX y 23 ciudades más a Nueva York! – $4,776   \n",
      "\n",
      "                                                 url       date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel... 2017-12-11  \n",
      "1  http://www.vuelax.com/2017/12/07/gdl-a-panama-... 2017-12-07  \n",
      "2  http://www.vuelax.com/2017/12/04/mty-a-cancun-... 2017-12-04  \n",
      "3  http://www.vuelax.com/2017/11/24/2x1-full-brasil/ 2017-11-24  \n",
      "4  http://www.vuelax.com/2017/11/17/cdmx-y-23-ciu... 2017-11-17  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127 entries, 0 to 126\n",
      "Data columns (total 3 columns):\n",
      "label    127 non-null object\n",
      "url      127 non-null object\n",
      "date     127 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 3.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0, parse_dates=['date'], encoding='utf-8')\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"), encoding='utf-8')\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 127 entries, 0 to 126\n",
      "Data columns (total 3 columns):\n",
      "label    127 non-null object\n",
      "url      127 non-null object\n",
      "date     127 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "still_dirty_df = pd.read_csv(join(base_dir, \"still_dirty.csv\"), index_col = 0, encoding='utf-8')\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      "origin         42 non-null object\n",
      "destination    42 non-null object\n",
      "price          42 non-null object\n",
      "url            42 non-null object\n",
      "date           42 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 3 columns):\n",
      "label    85 non-null object\n",
      "url      85 non-null object\n",
      "date     85 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "location_regex_note = re.compile('¡([\\w0-9,\\s\\.]+) [a|A] ([\\w0-9,\\s\\.]+)!\\s[-|–|\"desde\"|\"DESDE\"]\\s*\\$([0-9\\.,]+)')\n",
    "\n",
    "\n",
    "clean_values = []\n",
    "non_clean_values = []\n",
    "\n",
    "for index, row in still_dirty_df.iterrows():\n",
    "    label = row['label']\n",
    "    find = location_regex_note.search(label)\n",
    "    if find:\n",
    "        de = find.group(1)\n",
    "        a = find.group(2)\n",
    "        por = find.group(3)\n",
    "        clean_values.append([de, a, por, row[\"url\"], row[\"date\"]])\n",
    "    else:\n",
    "        non_clean_values.append(row.values)\n",
    "\n",
    "\n",
    "clean2 = pd.DataFrame(clean_values, columns= [\"origin\", \"destination\", \"price\", \"url\", \"date\"])\n",
    "print(clean2.info())\n",
    "\n",
    "still_dirty_df = pd.DataFrame(non_clean_values, columns= [\"label\", \"url\", \"date\"])\n",
    "print(still_dirty_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Clean ==\n",
      "         date destination note      origin   price  \\\n",
      "0  2018-01-21      India   NaN        CDMX   8,621   \n",
      "1  2018-01-20     La Paz   NaN         GDL   1,195   \n",
      "2  2018-01-20      India   NaN        CDMX   8,621   \n",
      "3  2018-01-19      China   NaN  GDL y CDMX  11,046   \n",
      "4  2018-01-19  Ámsterdam   NaN         CUN   9,339   \n",
      "\n",
      "                                                 url  \n",
      "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-...  \n",
      "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-...  \n",
      "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-...  \n",
      "3  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...  \n",
      "4  http://www.vuelax.com/2018/01/19/cun-a-amsterd...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1350 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1350 non-null object\n",
      "destination    1350 non-null object\n",
      "note           11 non-null object\n",
      "origin         1350 non-null object\n",
      "price          1350 non-null object\n",
      "url            1350 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 73.8+ KB\n",
      "None\n",
      "\n",
      "== Dirty ==\n",
      "                                               label  \\\n",
      "0  CDMX a Barcelona (escala larga en Canadá) + Ba...   \n",
      "1                                MTY a Cancún $1,455   \n",
      "2                                ¡2×1! ¡Full Brasil!   \n",
      "3  ¡Sin pasar EEUU! CDMX y 23 ciudades más a Vanc...   \n",
      "4  CDMX y más ciudades a Lima, Perú. ¡Opción de h...   \n",
      "\n",
      "                                                 url        date  \n",
      "0  http://www.vuelax.com/2017/12/11/cdmx-a-barcel...  2017-12-11  \n",
      "1  http://www.vuelax.com/2017/12/04/mty-a-cancun-...  2017-12-04  \n",
      "2  http://www.vuelax.com/2017/11/24/2x1-full-brasil/  2017-11-24  \n",
      "3  http://www.vuelax.com/2017/11/15/sin-pasar-eeu...  2017-11-15  \n",
      "4  http://www.vuelax.com/2017/11/13/cdmx-y-mas-ci...  2017-11-13  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 3 columns):\n",
      "label    85 non-null object\n",
      "url      85 non-null object\n",
      "date     85 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0, encoding='utf-8')\n",
    "clean = pd.concat([clean, clean2])\n",
    "\n",
    "print(\"== Clean ==\")\n",
    "print(clean.head())\n",
    "print(clean.info())\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"), encoding='utf-8')\n",
    "print()\n",
    "print(\"== Dirty ==\")\n",
    "print(still_dirty_df.head())\n",
    "print(still_dirty_df.info())\n",
    "still_dirty_df.to_csv(join(base_dir, \"still_dirty.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         origin                       destination    price\n",
      "12                   CDMX y GDL             Chihuahua y viceversa    1,814\n",
      "13                         CDMX  El Calafate, Patagonia Argentina   10,829\n",
      "14       CDMX y 23 ciudades más                 San Francisco, CA    3,795\n",
      "15       CDMX y 23 ciudades más                   Toronto, Canadá   8,486.\n",
      "16                         CDMX                 Santa Clara, Cuba    4,666\n",
      "17       CDMX y 23 ciudades más                  Montreal, Canadá   8,367.\n",
      "18                         CDMX                            Madrid  11,866.\n",
      "19                         CDMX                         Barcelona  11,921.\n",
      "20         CDMX, MTY, GDL y CUN                  El Cairo, Egipto  10,038.\n",
      "21                         CDMX             San Juan, Puerto Rico    4,292\n",
      "22                   CDMX y GDL         San Francisco, California    3,970\n",
      "23                         CDMX                    Beirut, Líbano  13,219.\n",
      "24  CDMX, GDL y 22 ciudades más                           Chicago    3,388\n",
      "25       CDMX y 23 ciudades más                      Roma, Italia   16,275\n",
      "26                         CDMX                    Varadero, Cuba    5,526\n",
      "27                         CDMX                   Honolulu, Hawai   10,931\n",
      "28                   CDMX y GDL                   Bali, Indonesia   13,808\n",
      "29                   CDMX y GDL                      Osaka, Japón   12,227\n",
      "30                   CDMX y GDL                 Anchorage, Alaska    9,680\n",
      "31         CDMX, MTY, GDL y CUN                  El Cairo, Egipto   9,686.\n",
      "32                         CDMX                 Sydney, Australia   18,312\n",
      "33                   CDMX y GDL                     San Francisco    4,110\n",
      "34                         CDMX                       Nueva Delhi   10,921\n",
      "35                         CDMX                Edimburgo, Escocia   17,963\n",
      "36                         CDMX                 Santa Clara, Cuba    5,438\n",
      "37                         CDMX                 Cancún en Navidad    2,489\n",
      "38                         CDMX                        Oranjestad   7,564.\n",
      "39                         CDMX                           Londres   13,917\n",
      "40                         CDMX                          Chetumal    1,462\n",
      "41                         CDMX                         La Habana    3,720\n",
      "                         origin                       destination   price\n",
      "12                   CDMX y GDL             Chihuahua y viceversa   1,814\n",
      "13                         CDMX  El Calafate, Patagonia Argentina  10,829\n",
      "14       CDMX y 23 ciudades más                 San Francisco, CA   3,795\n",
      "15       CDMX y 23 ciudades más                   Toronto, Canadá   8,486\n",
      "16                         CDMX                 Santa Clara, Cuba   4,666\n",
      "17       CDMX y 23 ciudades más                  Montreal, Canadá   8,367\n",
      "18                         CDMX                            Madrid  11,866\n",
      "19                         CDMX                         Barcelona  11,921\n",
      "20         CDMX, MTY, GDL y CUN                  El Cairo, Egipto  10,038\n",
      "21                         CDMX             San Juan, Puerto Rico   4,292\n",
      "22                   CDMX y GDL         San Francisco, California   3,970\n",
      "23                         CDMX                    Beirut, Líbano  13,219\n",
      "24  CDMX, GDL y 22 ciudades más                           Chicago   3,388\n",
      "25       CDMX y 23 ciudades más                      Roma, Italia  16,275\n",
      "26                         CDMX                    Varadero, Cuba   5,526\n",
      "27                         CDMX                   Honolulu, Hawai  10,931\n",
      "28                   CDMX y GDL                   Bali, Indonesia  13,808\n",
      "29                   CDMX y GDL                      Osaka, Japón  12,227\n",
      "30                   CDMX y GDL                 Anchorage, Alaska   9,680\n",
      "31         CDMX, MTY, GDL y CUN                  El Cairo, Egipto   9,686\n",
      "32                         CDMX                 Sydney, Australia  18,312\n",
      "33                   CDMX y GDL                     San Francisco   4,110\n",
      "34                         CDMX                       Nueva Delhi  10,921\n",
      "35                         CDMX                Edimburgo, Escocia  17,963\n",
      "36                         CDMX                 Santa Clara, Cuba   5,438\n",
      "37                         CDMX                 Cancún en Navidad   2,489\n",
      "38                         CDMX                        Oranjestad   7,564\n",
      "39                         CDMX                           Londres  13,917\n",
      "40                         CDMX                          Chetumal   1,462\n",
      "41                         CDMX                         La Habana   3,720\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0)\n",
    "\n",
    "strip_blanks = lambda x: x.strip()\n",
    "strip_dot = lambda x: x.strip('.')\n",
    "\n",
    "print(clean[['origin','destination','price']].tail(30))\n",
    "clean.origin = clean.origin.apply(strip_blanks)\n",
    "clean.destination = clean.destination.apply(strip_blanks)\n",
    "clean.price = clean.price.apply(strip_dot)\n",
    "print(clean[['origin','destination','price']].tail(30))\n",
    "\n",
    "\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1350 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1350 non-null object\n",
      "destination    1350 non-null object\n",
      "note           11 non-null object\n",
      "origin         1350 non-null object\n",
      "price          1350 non-null object\n",
      "url            1350 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 73.8+ KB\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0, encoding='utf-8')\n",
    "clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_price = lambda price: float(price.replace(',',''))\n",
    "clean.price = clean['price'].apply(convert_price)\n",
    "clean.to_csv(join(base_dir, \"clean.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1350 entries, 0 to 41\n",
      "Data columns (total 6 columns):\n",
      "date           1350 non-null datetime64[ns]\n",
      "destination    1350 non-null object\n",
      "note           11 non-null object\n",
      "origin         1350 non-null object\n",
      "price          1350 non-null float64\n",
      "url            1350 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 73.8+ KB\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(join(base_dir, \"clean.csv\"), index_col = 0, parse_dates=['date'], encoding='utf-8')\n",
    "clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tolist  = lambda origin: [t.strip() for t in nltk.tokenize.regexp.regexp_tokenize(origin, r'[y,\\.\\?!\"]\\s*', gaps=True)]\n",
    "\n",
    "separate_origins = []\n",
    "\n",
    "for index, row in clean.iterrows():\n",
    "    origins = tolist(row['origin'])\n",
    "    for origin in origins:\n",
    "        separate_origins.append([origin, row['destination'],\n",
    "                                row['date'], row['price'],\n",
    "                                row['note'], row['url']])\n",
    "        \n",
    "separa_origin_df = pd.DataFrame(separate_origins, columns=['origin', 'destination',\n",
    "                                                           'date', 'price', \n",
    "                                                           'note', 'url'])\n",
    "\n",
    "separa_origin_df.to_csv(join(base_dir, \"separate_origins.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geocoder\n",
    "\n",
    "locations = sorted(set(list(separa_origin_df.origin.unique()) + list(separa_origin_df.destination.unique())))\n",
    "\n",
    "real_locations = {'CDMX': 'Ciudad de México', \n",
    "                  'CUN': 'Cancún', 'GDL': 'Guadalajara',\n",
    "                  'L.A.': 'Los Angeles', 'LA': 'Los Angeles',\n",
    "                  'MTY': 'Monterrey', 'NYC': 'New York City', \n",
    "                  'PUE': 'Puebla', 'QRO': 'Querétaro',\n",
    "                  'SLP': 'San Luis Potosí',\n",
    "                  'TIJ': 'Tijuana', 'VER': 'Veracruz'\n",
    "                 }\n",
    "\n",
    "location_dic = {}\n",
    "for l in locations[21:]:\n",
    "    l = real_locations.get(l, l)\n",
    "    g = geocoder.google(l,key = 'GOOGLE KEY API')\n",
    "    if g.ok:\n",
    "        location_dic[l] = g.latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_long</th>\n",
       "      <th>destination</th>\n",
       "      <th>destination_lat</th>\n",
       "      <th>destination_long</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>19.432608</td>\n",
       "      <td>-99.133208</td>\n",
       "      <td>India</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>http://www.vuelax.com/2018/01/21/cdmx-a-india-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guadalajara</td>\n",
       "      <td>20.659699</td>\n",
       "      <td>-103.349609</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>-16.489689</td>\n",
       "      <td>-68.119294</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>http://www.vuelax.com/2018/01/20/gdl-a-la-paz-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>19.432608</td>\n",
       "      <td>-99.133208</td>\n",
       "      <td>India</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>8621.0</td>\n",
       "      <td>http://www.vuelax.com/2018/01/20/cdmx-a-india-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guadalajara</td>\n",
       "      <td>20.659699</td>\n",
       "      <td>-103.349609</td>\n",
       "      <td>China</td>\n",
       "      <td>35.861660</td>\n",
       "      <td>104.195397</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>11046.0</td>\n",
       "      <td>http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>19.432608</td>\n",
       "      <td>-99.133208</td>\n",
       "      <td>China</td>\n",
       "      <td>35.861660</td>\n",
       "      <td>104.195397</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>11046.0</td>\n",
       "      <td>http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             origin  origin_lat  origin_long destination  destination_lat  \\\n",
       "0  Ciudad de México   19.432608   -99.133208       India        20.593684   \n",
       "1       Guadalajara   20.659699  -103.349609      La Paz       -16.489689   \n",
       "2  Ciudad de México   19.432608   -99.133208       India        20.593684   \n",
       "3       Guadalajara   20.659699  -103.349609       China        35.861660   \n",
       "4  Ciudad de México   19.432608   -99.133208       China        35.861660   \n",
       "\n",
       "   destination_long       date    price  \\\n",
       "0         78.962880 2018-01-21   8621.0   \n",
       "1        -68.119294 2018-01-20   1195.0   \n",
       "2         78.962880 2018-01-20   8621.0   \n",
       "3        104.195397 2018-01-19  11046.0   \n",
       "4        104.195397 2018-01-19  11046.0   \n",
       "\n",
       "                                                 url note  \n",
       "0  http://www.vuelax.com/2018/01/21/cdmx-a-india-...  NaN  \n",
       "1  http://www.vuelax.com/2018/01/20/gdl-a-la-paz-...  NaN  \n",
       "2  http://www.vuelax.com/2018/01/20/cdmx-a-india-...  NaN  \n",
       "3  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...  NaN  \n",
       "4  http://www.vuelax.com/2018/01/19/gdl-y-cdmx-a-...  NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_name = lambda l: real_locations.get(l, l)\n",
    "get_lat = lambda l: location_dic.get(l, (np.nan,np.nan))[0]\n",
    "get_long = lambda l: location_dic.get(l, (np.nan,np.nan))[1]\n",
    "\n",
    "separa_origin_df['origin'] = separa_origin_df.origin.apply(get_real_name)\n",
    "separa_origin_df['origin_lat'] = separa_origin_df.origin.apply(get_lat)\n",
    "separa_origin_df['origin_long'] = separa_origin_df.origin.apply(get_long)\n",
    "separa_origin_df['destination_lat'] = separa_origin_df.destination.apply(get_lat)\n",
    "separa_origin_df['destination_long'] = separa_origin_df.destination.apply(get_long)\n",
    "\n",
    "separa_origin_df = separa_origin_df[['origin','origin_lat','origin_long',\n",
    "                                     'destination','destination_lat','destination_long',\n",
    "                                     'date', 'price', 'url','note']]\n",
    "separa_origin_df.to_csv(join(base_dir, \"separate_origins.csv\"), encoding='utf-8')\n",
    "separa_origin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
